{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       userID  itemID  rating   timestamp\n",
      "0        2409     256     5.0  1114232409\n",
      "1        2533    1116     4.0  1351541044\n",
      "2         422     369     4.0  1068357977\n",
      "3         840      53     4.0  1010512429\n",
      "4         521     167     3.5  1107571443\n",
      "...       ...     ...     ...         ...\n",
      "97837    2606     703     4.5  1125191720\n",
      "97838    1338     490     2.0   939134372\n",
      "97839    2081    1115     2.0  1094481868\n",
      "97840    1942     597     3.0  1122004393\n",
      "97841    2219      55     4.5  1341922541\n",
      "\n",
      "[97842 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "header = ['userID','itemID','rating','timestamp']\n",
    "df = pd.read_csv('train.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4124\n"
     ]
    }
   ],
   "source": [
    "n_users = df.userID.unique().shape[0]\n",
    "n_items = df.loc[:,['itemID']].max()['itemID']\n",
    "#print(n_items)\n",
    "#print(type(n_items))\n",
    "#print('number of user is '+ str(n_users) + ' | Number of item = ' + str(n_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn import model_selection as ms\n",
    "#train_data,test_data = ms.train_test_split(df, test_size = 0.25)\n",
    "#print(df)\n",
    "#print(train_data)\n",
    "#print(type(train_data))\n",
    "#print(train_data.shape)\n",
    "#print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_matrix = np.zeros((n_users,n_items))\n",
    "for line in df.itertuples():\n",
    "    #print(line)\n",
    "    train_data_matrix[int(line[1])-1, int(line[2])-1] = line[3]\n",
    "#print(train_data_matrix)\n",
    "train_data_matrix[:,0]+=1e-9\n",
    "train_data_matrix[0]+=1e-9\n",
    "#test_data_matrix = np.zeros((n_users, n_items))\n",
    "#for line in test_data.itertuples():\n",
    "#    test_data_matrix[line[1]-1, line[2]-1] = line[3]\n",
    "#test_data_matrix[:,0]+=1e-9\n",
    "#test_data_matrix[0]+=1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics.pairwise import pairwise_distances\n",
    "#user_similarity = pairwise_distances(train_data_matrix, metric = \"cosine\")\n",
    "#item_similarity = pairwise_distances(train_data_matrix.T, metric = \"cosine\")\n",
    "#print(user_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_user_similarity(train_data_matrix):\n",
    "    num_user=train_data_matrix.shape[0]\n",
    "    pss_user=np.ones((num_user,num_user))\n",
    "    mean_user = np.average(train_data_matrix,1,weights=np.int64(train_data_matrix>0))#求平均值\n",
    "    for i in tqdm(range(num_user)):#进度条\n",
    "        for j in range(i,num_user):\n",
    "            if i==j :\n",
    "                pss_user[i][j]=1\n",
    "            else :\n",
    "                #筛选共同打分的item索引\n",
    "                ind = np.nonzero(train_data_matrix[i]*train_data_matrix[j])\n",
    "                if len(ind[0])==1:\n",
    "                    pss_user[i][j]=0\n",
    "                    continue\n",
    "                #计算相似度\n",
    "                pss_user[i][j] = pss_user[j][i] = np.sum((train_data_matrix[i][ind]-mean_user[i])*(train_data_matrix[j][ind]-mean_user[j]))\\\n",
    "                                    /(np.sqrt(np.sum(np.square(train_data_matrix[i][ind]-mean_user[i])))*np.sqrt(np.sum(np.square(train_data_matrix[j][ind]-mean_user[j]))))\n",
    "    return pss_user;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2967/2967 [03:13<00:00, 15.35it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00000000e+00 -2.58058655e-02 -1.52544074e-08 ... -2.04576184e-08\n",
      "   7.01865093e-02  2.97128329e-01]\n",
      " [-2.58058655e-02  1.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "   7.02270566e-01 -1.85436195e-01]\n",
      " [-1.52544074e-08  1.00000000e+00  1.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " ...\n",
      " [-2.04576184e-08  1.00000000e+00  1.00000000e+00 ...  1.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 7.01865093e-02  7.02270566e-01  1.00000000e+00 ...  1.00000000e+00\n",
      "   1.00000000e+00  2.22824800e-01]\n",
      " [ 2.97128329e-01 -1.85436195e-01  1.00000000e+00 ...  1.00000000e+00\n",
      "   2.22824800e-01  1.00000000e+00]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pss_user = count_user_similarity(train_data_matrix)\n",
    "print(pss_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_item_similarity(train_data_matrix):\n",
    "    train_data_matrix_T = np.transpose(train_data_matrix)\n",
    "    num_item=train_data_matrix_T.shape[0]\n",
    "    print(num_item)\n",
    "    pss_item=np.ones((num_item,num_item))\n",
    "    #mean_item = np.average(train_data_matrix,0,weights=np.int64(train_data_matrix>0))#求平均值\n",
    "    #print(mean_item)\n",
    "    for i in tqdm(range(num_item)):\n",
    "        for j in range(i,num_item):\n",
    "            if i==j :\n",
    "                pss_item[i][j]=1\n",
    "            else :\n",
    "                #筛选共同打分的item索引\n",
    "                ind = np.nonzero(train_data_matrix_T[i]*train_data_matrix_T[j])\n",
    "                #if len(ind[0])==1:\n",
    "                #    pss_item[i][j]=0\n",
    "                    continue\n",
    "                #计算相似度\n",
    "                pss_item[i][j] = pss_item[j][i] = np.sum((train_data_matrix_T[i][ind])*(train_data_matrix_T[j][ind]))\\\n",
    "                                    /(np.sqrt(np.sum(np.square(train_data_matrix_T[i][ind])))*np.sqrt(np.sum(np.square(train_data_matrix_T[j][ind]))))\n",
    "    return pss_item;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4124 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4124/4124 [07:30<00:00,  9.15it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.44570899 0.27418737 ... 0.4472136  0.         0.36771366]\n",
      " [0.44570899 1.         0.94657329 ... 0.83205029 0.         0.9587289 ]\n",
      " [0.27418737 0.94657329 1.         ... 0.         0.         0.94906888]\n",
      " ...\n",
      " [0.4472136  0.83205029 1.         ... 1.         0.         1.        ]\n",
      " [1.         1.         1.         ... 1.         1.         0.        ]\n",
      " [0.36771366 0.9587289  0.94906888 ... 1.         1.         1.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pss_item = count_item_similarity(train_data_matrix)\n",
    "print(pss_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4124, 4124)\n"
     ]
    }
   ],
   "source": [
    "print(pss_item.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_nozero(ratings, kind):\n",
    "    if kind == 'user':\n",
    "        user_bias = np.zeros(ratings.shape[0])\n",
    "        for i in range(0, ratings.shape[0]):\n",
    "            number = amount = 0\n",
    "            for j in range(0, ratings.shape[1]):\n",
    "                if(ratings[i,j] != 0):\n",
    "                    number += 1\n",
    "                    amount += ratings[i,j]\n",
    "            user_bias[i] = amount/number\n",
    "        return user_bias\n",
    "    if kind == 'item':\n",
    "        item_bias = np.zeros(ratings.shape[1])\n",
    "        for i in range(0, ratings.shape[1]):\n",
    "            number = amount = 0\n",
    "            for j in range(0, ratings.shape[0]):\n",
    "                if(ratings[j,i] != 0):\n",
    "                    number += 1\n",
    "                    amount += ratings[j,i]\n",
    "            item_bias[i] = amount/number\n",
    "        return item_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_topk_nobias(ratings, similarity, kind='user', k=40):\n",
    "    tmp1 = np.zeros(ratings.shape)\n",
    "    tmp2 = np.zeros(ratings.shape[0])\n",
    "    pred = np.zeros(ratings.shape)\n",
    "    if kind == 'user':\n",
    "        #user_bias = ratings.mean(axis=1)#按行求平均值\n",
    "        user_bias = mean_nozero(ratings, 'user')\n",
    "        ratings = (ratings - user_bias[:, np.newaxis]).copy()#user的打分减去其打分集合的平均分\n",
    "#         for i in range(ratings.shape[0]):\n",
    "#             for j in range(ratings.shape[1]):\n",
    "#                 for m in range(ratings.shape[0]):\n",
    "#                     if(ratings[m][j] < 1e-5):\n",
    "#                         continue\n",
    "#                     tmp1[i][j] += similarity[i,m]*ratings[m,j]\n",
    "#                     tmp2[i] += similarity[i,m]\n",
    "        tmp1 = similarity@np.vectorize(lambda x: 0 if x < 1e-6 else x)(ratings)\n",
    "        tmp2 = np.sum(similarity@np.vectorize(lambda x : 0 if x < 1e-6 else 1 (ratings), axis = 1))\n",
    "        for k in range(ratings.shape[0]):\n",
    "            pred[k] = tmp1[k]/tmp2[k]\n",
    "        pred+=user_bias[:,np.newaxis]\n",
    "    if kind == 'item':\n",
    "        #item_bias = ratings.mean(axis=0)\n",
    "        item_bias = mean_nozero(ratings, 'item')\n",
    "        print(item_bias)\n",
    "        ratings = (ratings - item_bias[np.newaxis, :]).copy()\n",
    "        for j in range(ratings.shape[1]):\n",
    "            top_k_items = [np.argsort(similarity[:,j])[:-k-1:-1]]\n",
    "            for i in range(ratings.shape[0]):\n",
    "                for m in range(len(top_k_users)):\n",
    "                    if(ratings[i][j] < 1e-5 or all(ratings[top_k_users[m]][j]) < 1e-5):\n",
    "                        del top_k_users[m]\n",
    "                pred[i, j] = similarity[j, :][top_k_items].dot(ratings[i, :][top_k_items].T) \n",
    "                pred[i, j] /= np.sum(np.abs(similarity[j, :][top_k_items])) \n",
    "        pred += item_bias[np.newaxis, :]\n",
    "        \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(rating, similarity, type = 'user'):\n",
    "    if(type == 'user'):\n",
    "        mean_user_rating = rating.mean(axis = 1)\n",
    "        print(mean_user_rating)\n",
    "        rating_diff = (rating - mean_user_rating[:,np.newaxis])\n",
    "        #pred = mean_user_rating[:,np.newaxis] + similarity.dot(rating_diff) / np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "    elif type == 'item':\n",
    "        print(rating.shape)\n",
    "        print(similarity.shape)\n",
    "        #pred = rating.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)])\n",
    "    #return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-43afb04ba99d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0muser_based_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_topk_nobias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_matrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpss_user\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'user'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_based_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-117-4160e634cbbf>\u001b[0m in \u001b[0;36mpredict_topk_nobias\u001b[0;34m(ratings, similarity, kind, k)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#                     tmp2[i] += similarity[i,m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtmp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1e-6\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mtmp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1e-6\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtmp2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'axis'"
     ]
    }
   ],
   "source": [
    "user_based_pred = predict_topk_nobias(train_data_matrix,pss_user, 'user',40)\n",
    "print(user_based_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2967, 4124)\n"
     ]
    }
   ],
   "source": [
    "print(user_based_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_result = pd.DataFrame(user_based_pred)\n",
    "#print(df_result)\n",
    "df_user_result.to_csv('user_based_result.csv',index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:18: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:19: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.19224147  0.42063004  0.22049574 ... -0.1555696  -0.01494646\n",
      "   0.38140799]\n",
      " [ 0.19234147  0.42073004  0.22059574 ... -0.1554696  -0.01484646\n",
      "   0.38150799]\n",
      " [ 0.19224147  0.42063004  0.22049574 ... -0.1555696  -0.01494646\n",
      "   0.38140799]\n",
      " ...\n",
      " [ 0.19224147  0.42063004  0.22049574 ... -0.1555696  -0.01494646\n",
      "   0.38140799]\n",
      " [ 0.19224147  0.42063004  0.22049574 ... -0.1555696  -0.01494646\n",
      "   0.38140799]\n",
      " [ 0.25869968  0.55495623  0.37946964 ... -0.0555696  -0.01494646\n",
      "   0.48140799]]\n"
     ]
    }
   ],
   "source": [
    "item_based_pred = predict_topk_nobias(train_data_matrix,pss_item,'item',40)\n",
    "print(item_based_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('predict2.csv','w')\n",
    "f.write('dataID,rating\\n')\n",
    "for i in range(test_data_matrix.shape[0]):\n",
    "    predict_matrix[i][0] = i\n",
    "    predict_matrix[i][1] = res[test_data_matrix[i][0]][test_data_matrix[i][1]]\n",
    "    f.write('%d,%.8f\\n'%(predict_matrix[i][0],predict_matrix[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item_result = pd.DataFrame(item_based_pred)\n",
    "#print(df_result)\n",
    "df_item_result.to_csv('item_based_result.csv',index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "def rmse(prediction, ground_truth):\n",
    "    prediction = prediction[ground_truth.nonzero()].flatten()\n",
    "    ground_truth = ground_truth[ground_truth.nonzero()].flatten()\n",
    "    return sqrt(mean_squared_error(prediction, ground_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       userID  itemID\n",
      "0        2345     468\n",
      "1         381     181\n",
      "2        2679     320\n",
      "3        1638     632\n",
      "4        1562      40\n",
      "...       ...     ...\n",
      "39674     886     273\n",
      "39675     332      10\n",
      "39676    2966     133\n",
      "39677    2855     158\n",
      "39678    2748      40\n",
      "\n",
      "[39679 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('test_index.csv')\n",
    "print(df_test)#这里为什么没有打分？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_users_test = df.userID.unique().shape[0]\n",
    "#n_items_test = df.loc[:,['itemID']].max()['itemID']\n",
    "#test_data_matrix = np.zeros(n_users, n_items)\n",
    "#for line in df_test.itertuples():\n",
    "#    test_data_matrix[int(line[1])-1, int(line[2])-1] = \n",
    "#precise = rmse(user_based_pred,test_data_matrix)\n",
    "#print(precise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test = df_test.values\n",
    "#precise = rmse(user_based_pred,test_data_matrix)\n",
    "#print(precise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
